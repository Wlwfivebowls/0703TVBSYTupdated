
import streamlit as st
import pandas as pd

st.set_page_config(page_title="ðŸ“Š YouTube ç›´æ’­é »é“åœ¨ç·šäººæ•¸åˆ†æž", layout="wide")

# å…¬é–‹ Google Sheet CSV é€£çµ
CSV_URL = "https://docs.google.com/spreadsheets/d/1DIz9Cd5iSr1ssNkyYgvBshwKcxfkdraOYilXbXzLXhU/export?format=csv&gid=0"

@st.cache_data(ttl=600)
def load_data():
    df = pd.read_csv(CSV_URL, encoding='utf-8')
    df = df.dropna(how='all')  # ç§»é™¤ç©ºç™½åˆ—
    df.columns = df.iloc[0]    # ç¬¬ä¸€åˆ—ç‚ºæ¬„ä½åç¨±
    df = df[1:]                 # ç§»é™¤æ¬„ä½åˆ—
    df = df.reset_index(drop=True)
    return df

def parse_data(df):
    # å–å‡ºé »é“åç¨±åˆ—
    df.columns.values[0:3] = ['é »é“é€£çµ', 'é »é“åç¨±', 'å½±ç‰‡æ¨™é¡Œ']
    channel_names = df['é »é“åç¨±'].tolist()

    # å°‡æ™‚é–“æ¬„è½‰ç½®æˆé•·æ ¼å¼
    df_long = pd.melt(df, id_vars=['é »é“é€£çµ', 'é »é“åç¨±', 'å½±ç‰‡æ¨™é¡Œ'],
                      var_name='æ™‚é–“', value_name='åœ¨ç·šäººæ•¸')
    df_long['åœ¨ç·šäººæ•¸'] = pd.to_numeric(df_long['åœ¨ç·šäººæ•¸'], errors='coerce')
    df_long['æ™‚é–“'] = pd.to_datetime(df_long['æ™‚é–“'], errors='coerce')
    df_long = df_long.dropna(subset=['åœ¨ç·šäººæ•¸', 'æ™‚é–“'])

    return df_long

def show_dashboard(df_long):
    st.title("ðŸ“Š YouTube ç›´æ’­é »é“åœ¨ç·šäººæ•¸åˆ†æžï¼ˆé›²ç«¯è‡ªå‹•æ›´æ–°ï¼‰")

    # æ™‚é–“ç¯©é¸å™¨
    min_time = df_long['æ™‚é–“'].min()
    max_time = df_long['æ™‚é–“'].max()
    start_time, end_time = st.slider("é¸æ“‡åˆ†æžæ™‚é–“å€é–“ï¼š", min_value=min_time, max_value=max_time,
                                     value=(min_time, max_time), step=pd.Timedelta(hours=1))

    filtered = df_long[(df_long['æ™‚é–“'] >= start_time) & (df_long['æ™‚é–“'] <= end_time)]

    if filtered.empty:
        st.warning("âŒ ç¯©é¸å¾Œæ²’æœ‰è³‡æ–™ï¼Œè«‹èª¿æ•´æ™‚é–“å€é–“")
        return

    # é¡¯ç¤ºæŠ˜ç·šåœ–
    st.subheader("ðŸ“ˆ å„é »é“åœ¨ç·šäººæ•¸è¶¨å‹¢")
    chart_df = filtered.pivot_table(index='æ™‚é–“', columns='é »é“åç¨±', values='åœ¨ç·šäººæ•¸')
    st.line_chart(chart_df)

    # çµ±è¨ˆè¡¨
    st.subheader("ðŸ“‹ æ¯æ—¥å¹³å‡åœ¨ç·šäººæ•¸æ¯”è¼ƒè¡¨")
    daily_avg = filtered.groupby(['é »é“åç¨±', filtered['æ™‚é–“'].dt.date])['åœ¨ç·šäººæ•¸'].mean().reset_index()
    summary = daily_avg.groupby('é »é“åç¨±')['åœ¨ç·šäººæ•¸'].mean().reset_index(name='æ¯æ—¥å¹³å‡åœ¨ç·šäººæ•¸')
    summary['æ¯æ—¥åŠ ç¸½äººæ•¸'] = daily_avg.groupby('é »é“åç¨±')['åœ¨ç·šäººæ•¸'].sum().values
    summary = summary.sort_values(by='æ¯æ—¥å¹³å‡åœ¨ç·šäººæ•¸', ascending=False)

    # åŠ ä¸Šç¸½å¹³å‡ä¸€åˆ—
    avg_row = pd.DataFrame({
        'é »é“åç¨±': ['ç¸½å¹³å‡'],
        'æ¯æ—¥å¹³å‡åœ¨ç·šäººæ•¸': [summary['æ¯æ—¥å¹³å‡åœ¨ç·šäººæ•¸'].mean()],
        'æ¯æ—¥åŠ ç¸½äººæ•¸': [summary['æ¯æ—¥åŠ ç¸½äººæ•¸'].mean()]
    })
    summary = pd.concat([avg_row, summary], ignore_index=True)

    styled = summary.style.apply(lambda x: ['font-weight: bold; background-color: #FFD700; color: black'
                                            if x.name == 0 else '' for _ in x], axis=1)
    st.dataframe(styled, use_container_width=True)

# åŸ·è¡Œä¸»ç¨‹å¼
try:
    df_raw = load_data()
    df_long = parse_data(df_raw)
    show_dashboard(df_long)
except Exception as e:
    st.error(f"âŒ ç„¡æ³•è¼‰å…¥æˆ–è§£æžè³‡æ–™è¡¨ï¼Œè«‹æª¢æŸ¥æ ¼å¼æ˜¯å¦æ­£ç¢ºã€‚

éŒ¯èª¤è¨Šæ¯ï¼š{e}")
